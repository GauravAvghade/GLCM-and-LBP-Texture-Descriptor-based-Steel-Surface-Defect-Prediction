{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35363585-1d03-457a-8a5e-3c1e1c5a8917",
   "metadata": {},
   "source": [
    "# Features Extracting using LBP and GLCM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14ee5df-2228-4f17-b373-2c00357ba073",
   "metadata": {},
   "source": [
    "Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578d5e5d-6845-4a36-9d9e-8739c307a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, color, img_as_ubyte\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f8a7c-43b0-4ec9-bd7a-286a204d86b1",
   "metadata": {},
   "source": [
    "The code uses an augmented dataset created by augmentation forces, saved in defect list files. Extracted features will be saved in a .csv file containing values describing features extracted by GLCM and LBP to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeeaf70-41b1-4e7b-90d0-99b4f7688ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GLCM parameters\n",
    "glcm_params = [(1, 0), (1, np.pi/4), (1, np.pi/2), (1, 3*np.pi/4)]\n",
    "\n",
    "# Define the LBP parameters\n",
    "lbp_params = [(1, 8), (2, 8), (3, 8)]\n",
    "\n",
    "# Define the minimum and maximum values for normalization\n",
    "min_contrast = 0.0\n",
    "max_contrast = 1000.0\n",
    "min_energy = 0.0\n",
    "max_energy = 1.0\n",
    "min_entropy = 0.0\n",
    "max_entropy = 10.0  \n",
    "min_homogeneity = 0.0\n",
    "max_homogeneity = 1.0\n",
    "min_correlation = -1.0\n",
    "max_correlation = 1.0\n",
    "min_dissimilarity = 0.0  \n",
    "max_dissimilarity = 100.0  \n",
    "min_asm = 0.00001  \n",
    "max_asm = 0.05  \n",
    "\n",
    "# Initialize lists to store normalized results\n",
    "image_names = []\n",
    "normalized_features = []\n",
    "defect_types = []\n",
    "\n",
    "# List of defect categories (folder names)\n",
    "defect_categories = [\n",
    " # list of Defects \n",
    "]\n",
    "\n",
    "# Loop through the defect categories\n",
    "for category in defect_categories:\n",
    "    # Get a list of image filenames in the current category folder\n",
    "    image_filenames = os.listdir(category)\n",
    "\n",
    "    # Iterate through all image files in the folder\n",
    "    for image_filename in image_filenames:\n",
    "        if image_filename.endswith('.jpg'):\n",
    "            # Load the image\n",
    "            image = io.imread(os.path.join(category, image_filename))\n",
    "            \n",
    "            # Convert the image to grayscale\n",
    "            gray_image = color.rgb2gray(image)\n",
    "\n",
    "            # Convert the grayscale image to uint8\n",
    "            gray_image = img_as_ubyte(gray_image)\n",
    "\n",
    "            # Initialize a list to store features for this image\n",
    "            features = []\n",
    "\n",
    "            # Calculate GLCM features\n",
    "            for distance, angle in glcm_params:\n",
    "                # Calculate the GLCM\n",
    "                glcm = graycomatrix(gray_image, [distance], [angle], levels=256)\n",
    "\n",
    "                # Normalize the GLCM\n",
    "                glcm_normalized = glcm.astype(np.float32) / np.sum(glcm)\n",
    "\n",
    "                # Calculate texture properties\n",
    "                contrast = graycoprops(glcm_normalized, 'contrast')[0, 0]\n",
    "                energy = graycoprops(glcm_normalized, 'energy')[0, 0]\n",
    "                entropy = -np.sum(glcm_normalized * np.log(glcm_normalized + np.finfo(float).eps))\n",
    "                homogeneity = graycoprops(glcm_normalized, 'homogeneity')[0, 0]\n",
    "                correlation = graycoprops(glcm_normalized, 'correlation')[0, 0]\n",
    "                dissimilarity = graycoprops(glcm_normalized, 'dissimilarity')[0, 0]\n",
    "                asm = graycoprops(glcm_normalized, 'ASM')[0, 0]\n",
    "\n",
    "                # Normalize the texture characteristics\n",
    "                normalized_contrast = (contrast - min_contrast) / (max_contrast - min_contrast)\n",
    "                normalized_energy = (energy - min_energy) / (max_energy - min_energy)\n",
    "                # Convert ASM to string, remove leading zeros, and convert back to float\n",
    "                normalized_entropy = float(str(entropy).lstrip('0'))\n",
    "                normalized_entropy = (normalized_entropy - min_entropy) / (max_entropy - min_entropy)\n",
    "                normalized_homogeneity = (homogeneity - min_homogeneity) / (max_homogeneity - min_homogeneity)\n",
    "                normalized_correlation = (correlation - min_correlation) / (max_correlation - min_correlation)\n",
    "                # Adjusted min and max values for dissimilarity and ASM\n",
    "                normalized_dissimilarity = (dissimilarity - min_dissimilarity) / (max_dissimilarity - min_dissimilarity)\n",
    "                # Convert ASM to string, remove leading zeros, and convert back to float\n",
    "                normalized_asm = float(str(asm).lstrip('0'))\n",
    "                normalized_asm = (normalized_asm - min_asm) / (max_asm - min_asm)\n",
    "\n",
    "                # Append the normalized results to the features list\n",
    "                features.extend([normalized_contrast, normalized_energy, normalized_entropy, normalized_homogeneity, normalized_correlation, normalized_dissimilarity, normalized_asm])\n",
    "\n",
    "            # Calculate LBP features\n",
    "            for lbp_radius, lbp_n_points in lbp_params:\n",
    "                # Calculate LBP features\n",
    "                lbp_image = local_binary_pattern(gray_image, lbp_n_points, lbp_radius, method='uniform')\n",
    "\n",
    "                # Calculate LBP histogram as features\n",
    "                lbp_hist, _ = np.histogram(lbp_image.ravel(), bins=np.arange(0, lbp_n_points + 3), range=(0, lbp_n_points + 2))\n",
    "\n",
    "                # Normalize the histogram\n",
    "                lbp_hist = lbp_hist.astype(np.float32)\n",
    "                lbp_hist /= (lbp_hist.sum() + 1e-6)\n",
    "\n",
    "                # Add LBP features for the current parameter combination\n",
    "                features.extend(lbp_hist)\n",
    "            \n",
    "            # Append the features for this image to the result\n",
    "            normalized_features.append(features)\n",
    "\n",
    "            # Append the defect type\n",
    "            defect_types.append(category)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "column_names = []\n",
    "\n",
    "# Add column names for GLCM features\n",
    "for distance, angle in glcm_params:\n",
    "    for char in ['Contrast', 'Energy', 'Entropy', 'Homogeneity', 'Correlation', 'Dissimilarity', 'ASM']:\n",
    "        column_names.append(f' {char} (d={distance}, a={angle:.2f})')\n",
    "\n",
    "# Add column names for LBP features\n",
    "for lbp_radius, lbp_n_points in lbp_params:\n",
    "    column_names.extend([f'LBP_{lbp_radius}_{lbp_n_points}_{i}' for i in range(lbp_n_points + 2)])\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(normalized_features, columns=column_names)\n",
    "\n",
    "# Add the defect type column\n",
    "df['Defect'] = defect_types\n",
    "\n",
    "# Save the results in a CSV file\n",
    "output_filename = 'lbp_and_glcm_features.csv'\n",
    "df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f'Results saved to {output_filename}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9025ac-84ae-4955-bd35-9a3be1166cbe",
   "metadata": {},
   "source": [
    "# Checking Features in .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c185466-b5a8-4353-9b76-14eec9576ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "csv_file_path = \"lbp_and_glcm_features.csv\"\n",
    "\n",
    "# Use pandas to read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Number of rows and columns\n",
    "num_rows, num_columns = df.shape\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_columns}\")\n",
    "\n",
    "# Column names\n",
    "column_names = df.columns\n",
    "print(\"Column names:\", column_names)\n",
    "\n",
    "# View the first few rows\n",
    "print(\"First few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# View the last few rows\n",
    "print(\"Last few rows:\")\n",
    "print(df.tail())\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Summary statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# If you want to count non-null values in each column, you can use:\n",
    "print(df.count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
